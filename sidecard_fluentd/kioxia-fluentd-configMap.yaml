kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-config
  namespace: kioxia
data:
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>
  containers.input.conf: |-
    <source>
      @type tail
      path /logs/AccessLog/*.log
      pos_file /tmp/pep-app.pos
      tag app.kioxia.pep.accesslog        # 设置日志标签
      read_from_head true                 # Starts to read the logs from the head of the file or the last read position recorded in pos_file, not tail.
      <parse>
        @type apache2
      </parse>
    </source>

    <filter app.kioxia.pep.accesslog>
      @type record_transformer
      <record>
      hostname ${hostname}
      </record>
    </filter>

    <source>
      @type tail
      path /logs/accessLog.log
      pos_file /tmp/pep-app-cur.pos
      tag app.kioxia.pep.accesslog-current        # 设置日志标签
      read_from_head true                         # Starts to read the logs from the head of the file or the last read position recorded in pos_file, not tail.
      <parse>
        @type apache2
      </parse>
    </source>

    <filter app.kioxia.pep.accesslog-current>
      @type record_transformer
      <record>
      hostname ${hostname}
      </record>
    </filter>
  ###### 监听配置，一般用于日志聚合用 ######
  forward.input.conf: |-
    # 监听通过TCP发送的消息
    <source>
      @id forward
      @type forward
    </source>
  output.conf: |-
    <match **>
      @id elasticsearch
      @type elasticsearch
      include_tag_key true
      host <servicename.namespace.svc.cluster.local>  # 這邊記得修改相對應的serviceName以及namespace
      port 9200
      index_name fluentd.${tag}
      request_timeout    30s
      logstash_format true
      logstash_prefix app.kioxia.pep.accesslog
      flush_interval 1s
    </match>